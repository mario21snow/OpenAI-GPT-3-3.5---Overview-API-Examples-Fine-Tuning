{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install openai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "import pandas as pd\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%env OPENAI_API_KEY=<key>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set openai api key\n",
    "openai.api_key = os.getenv('OPENAI_API_KEY') # key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPT-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<OpenAIObject text_completion id=cmpl-6pz3XzafszXyz2okMfSnmEAIhltlx at 0x186bc6d59a0> JSON: {\n",
       "  \"choices\": [\n",
       "    {\n",
       "      \"finish_reason\": \"stop\",\n",
       "      \"index\": 0,\n",
       "      \"logprobs\": null,\n",
       "      \"text\": \"\\n\\nAI (Artificial Intelligence) is a branch of computer science that focuses on creating intelligent machines that can think and act like humans. AI systems are designed to learn from their environment and experiences, and use this knowledge to make decisions and solve problems. AI can be used in a variety of applications, such as robotics, natural language processing, computer vision, and machine learning.\"\n",
       "    }\n",
       "  ],\n",
       "  \"created\": 1677847447,\n",
       "  \"id\": \"cmpl-6pz3XzafszXyz2okMfSnmEAIhltlx\",\n",
       "  \"model\": \"text-davinci-003\",\n",
       "  \"object\": \"text_completion\",\n",
       "  \"usage\": {\n",
       "    \"completion_tokens\": 76,\n",
       "    \"prompt_tokens\": 4,\n",
       "    \"total_tokens\": 80\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = openai.Completion.create(\n",
    "    engine = 'text-davinci-003',\n",
    "    prompt = \"what is AI?\",\n",
    "    temperature = 0.2,\n",
    "    max_tokens = 256,\n",
    "    top_p = 1\n",
    ")\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "AI (Artificial Intelligence) is a branch of computer science that focuses on creating intelligent machines that can think and act like humans. AI systems are designed to learn from their environment and experiences, and use this knowledge to make decisions and solve problems. AI can be used in a variety of applications, such as robotics, natural language processing, computer vision, and machine learning.\n"
     ]
    }
   ],
   "source": [
    "print(response['choices'][0]['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask_gpt(prompt):\n",
    "    response = openai.Completion.create(\n",
    "    engine = 'text-davinci-003',\n",
    "    prompt = prompt,\n",
    "    temperature = 0.2,\n",
    "    max_tokens = 256,\n",
    "    top_p = 1\n",
    "    )\n",
    "    return response['choices'][0]['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Life is unpredictable and full of surprises! It's beautiful and challenging, and we should strive to make the most of it by being present and mindful.\n"
     ]
    }
   ],
   "source": [
    "print(ask_gpt(\"What do you think about life?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Positive\n"
     ]
    }
   ],
   "source": [
    "prompt = \"Identify the sentiment for the following sentence\\n This tutorial is really good!!\\n\\n Sentiment: \"\n",
    "print(ask_gpt(prompt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPT-3.5 (or) ChatGPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"finish_reason\": \"stop\",\n",
      "      \"index\": 0,\n",
      "      \"message\": {\n",
      "        \"content\": \"\\n\\nOpenAI is a non-profit research organization that is focused on developing advanced artificial intelligence in a safe and transparent manner. The company was founded in 2015 by a group of leading technology executives, including Tesla CEO Elon Musk and Sam Altman, and has since become one of the most prominent AI research organizations in the world. OpenAI's research focuses on developing cutting-edge AI technologies that can be used to benefit society, while also addressing concerns about the potential risks associated with powerful AI systems. The company has also developed several high-profile AI tools, including the popular GPT-3 language model, which can generate highly realistic and coherent natural language text.\",\n",
      "        \"role\": \"assistant\"\n",
      "      }\n",
      "    }\n",
      "  ],\n",
      "  \"created\": 1677848100,\n",
      "  \"id\": \"chatcmpl-6pzE42trd2uCPANFDdQvgRIMoBEnT\",\n",
      "  \"model\": \"gpt-3.5-turbo-0301\",\n",
      "  \"object\": \"chat.completion\",\n",
      "  \"usage\": {\n",
      "    \"completion_tokens\": 132,\n",
      "    \"prompt_tokens\": 23,\n",
      "    \"total_tokens\": 155\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "response = openai.ChatCompletion.create(\n",
    "    model = \"gpt-3.5-turbo\",\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": \"What is OpenAI?\"}\n",
    "    ]\n",
    "    )\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"finish_reason\": \"stop\",\n",
      "      \"index\": 0,\n",
      "      \"message\": {\n",
      "        \"content\": \"Elon Musk is the CEO of Tesla, a company that designs and manufactures electric cars, as well as SpaceX, a company that designs and launches advanced rockets and spacecraft. Sam Altman is also the CEO of OpenAI and was previously the president of startup accelerator Y Combinator.\",\n",
      "        \"role\": \"assistant\"\n",
      "      }\n",
      "    }\n",
      "  ],\n",
      "  \"created\": 1677848294,\n",
      "  \"id\": \"chatcmpl-6pzHCMpNJxTeMR6eNGjEZhMQnUO9G\",\n",
      "  \"model\": \"gpt-3.5-turbo-0301\",\n",
      "  \"object\": \"chat.completion\",\n",
      "  \"usage\": {\n",
      "    \"completion_tokens\": 59,\n",
      "    \"prompt_tokens\": 172,\n",
      "    \"total_tokens\": 231\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "response = openai.ChatCompletion.create(\n",
    "    model = \"gpt-3.5-turbo\",\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": \"What is OpenAI?\"},\n",
    "        {\"role\": \"assistant\", \"content\": \"\\n\\nOpenAI is a non-profit research organization that is focused on developing advanced artificial intelligence in a safe and transparent manner. The company was founded in 2015 by a group of leading technology executives, including Tesla CEO Elon Musk and Sam Altman, and has since become one of the most prominent AI research organizations in the world. OpenAI's research focuses on developing cutting-edge AI technologies that can be used to benefit society, while also addressing concerns about the potential risks associated with powerful AI systems. The company has also developed several high-profile AI tools, including the popular GPT-3 language model, which can generate highly realistic and coherent natural language text.\"},\n",
    "        {\"role\": \"user\", \"content\": \"What other companies that the executives own?\"},\n",
    "    ]\n",
    "    )\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"content\": \"Elon Musk is the CEO of Tesla, a company that designs and manufactures electric cars, as well as SpaceX, a company that designs and launches advanced rockets and spacecraft. Sam Altman is also the CEO of OpenAI and was previously the president of startup accelerator Y Combinator.\",\n",
      "  \"role\": \"assistant\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(response['choices'][0]['message'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "who are you?\n",
      "I am an AI language model designed to provide assistance and answer questions to the best of my abilities.\n",
      "what abilities you have?\n",
      "As an AI language model, I can understand and analyze natural language, generate text, perform simple calculations, provide information on a wide range of topics, and assist with various tasks and processes. However, my abilities are limited to what I have been programmed to do and the data I have been trained on.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "Interrupted by user",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-25-5db9b4f9ff4e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m     \u001b[0muser_input\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m     \u001b[0mformat_input\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m\"role\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m\"user\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"content\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34mf\"{user_input}\"\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[0mconversations\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mformat_input\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[1;34m(self, prompt)\u001b[0m\n\u001b[0;32m    858\u001b[0m                 \u001b[1;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    859\u001b[0m             )\n\u001b[1;32m--> 860\u001b[1;33m         return self._input_request(str(prompt),\n\u001b[0m\u001b[0;32m    861\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    862\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[1;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[0;32m    902\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    903\u001b[0m                 \u001b[1;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 904\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Interrupted by user\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    905\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    906\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Invalid Message:\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
     ]
    }
   ],
   "source": [
    "def chatGPT(messages):\n",
    "    response = openai.ChatCompletion.create(\n",
    "    model = \"gpt-3.5-turbo\",\n",
    "    messages = messages\n",
    "    )\n",
    "    return response['choices'][0]['message']\n",
    "\n",
    "conversations = [\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"}\n",
    "    ]\n",
    "\n",
    "while True:\n",
    "    user_input = input()\n",
    "    print()\n",
    "    format_input = {\"role\": \"user\", \"content\": f\"{user_input}\"}\n",
    "    conversations.append(format_input)\n",
    "    result = chatGPT(conversations)\n",
    "    print(result['content'])\n",
    "    conversations.append(result)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine Tuning GPT-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data should be in jsonl format\n",
    "# {\"prompt\": \"<prompt text>\", \"completion\": \"<ideal generated text>\"}\n",
    "# {\"prompt\": \"<prompt text>\", \"completion\": \"<ideal generated text>\"}\n",
    "# {\"prompt\": \"<prompt text>\", \"completion\": \"<ideal generated text>\"}\n",
    "# ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = [\n",
    "    \"Weather is good today!\",\n",
    "    \"I am okay now\",\n",
    "    \"I don't like the food\",\n",
    "    \"I love to travel\",\n",
    "    \"He is very bad at studying\",\n",
    "    \"The price is average\"\n",
    "]\n",
    "sentiments = [\n",
    "    \"positive\",\n",
    "    \"neutral\",\n",
    "    \"negative\",\n",
    "    \"positive\",\n",
    "    \"negative\",\n",
    "    \"neutral\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parse the input as list of jsons\n",
    "formatted_input = []\n",
    "for prompt, completion in zip(text, sentiments):\n",
    "    formatted_input.append({\"prompt\": f\"{prompt}\\n\", \"completion\": completion})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'prompt': 'Weather is good today!\\n', 'completion': 'positive'},\n",
       " {'prompt': 'I am okay now\\n', 'completion': 'neutral'},\n",
       " {'prompt': \"I don't like the food\\n\", 'completion': 'negative'}]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "formatted_input[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dump the json for training\n",
    "import json\n",
    "\n",
    "with open('training.jsonl', 'w') as outfile:\n",
    "    for entry in formatted_input:\n",
    "        json.dump(entry, outfile)\n",
    "        outfile.write('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validate the jsonl file before training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## run this in a command line to validate\n",
    "# openai tools fine_tunes.prepare_data -f <LOCAL_FILE>\n",
    "# openai tools fine_tunes.prepare_data -f training.jsonl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export OPENAI_API_KEY=\"<OPENAI_API_KEY>\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# openai api fine_tunes.create -t <TRAIN_FILE_ID_OR_PATH> -m <BASE_MODEL>\n",
    "# openai api fine_tunes.create -t training_prepared.jsonl -m davinci"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## test the fine tuned model\n",
    "# openai api completions.create -m <FINE_TUNED_MODEL> -p <YOUR_PROMPT>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use Fine Tuned Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "FINE_TUNED_MODEL = \"<model_name>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask_gpt(prompt):\n",
    "    response = openai.Completion.create(\n",
    "    engine = FINE_TUNED_MODEL,\n",
    "    prompt = prompt,\n",
    "    temperature = 0.2,\n",
    "    max_tokens = 256,\n",
    "    top_p = 1\n",
    "    )\n",
    "    return response['choices'][0]['text']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPT-Neo\n",
    "# GPT-J\n",
    "# T5\n",
    "# BLOOM\n",
    "# BERT\n",
    "# etc.,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advantages & Disadvantages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## advantages\n",
    "# create content\n",
    "# optimize content\n",
    "# solve most of the NLP tasks\n",
    "# generate code\n",
    "\n",
    "## disadvantages\n",
    "# knowledge is limited to 2021\n",
    "# it cannot constantly learn\n",
    "# cost constraint"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
